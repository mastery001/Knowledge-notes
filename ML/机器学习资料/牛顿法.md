[TOC]

##### 数学知识

- 分布律：设离散型随机变量X所有可能取到的值为$x_{k}(k=1,2,…)$，X取各个可能值的概率，即事件

  ${X=x_{k}}$的概率为：$P{X=x_{k}}=p_{k},k=1,2...$；


- 如果对于随机变量X的分布函数$F(x)$，存在非负函数$f(x)$，使得对于任意实数x有：

  ​				$F(x)=\int_{-\infty}^{x}f(t)dt$

  则称X为连续型随机变量，其中函数$f(x)$称为X的概率密度函数，简称概率密度。

- 联合分布律：设二维离散型随机变量(X,Y)所有可能取得值为$(x_{i},y{i}),i,j=1,2,...$记$P\{X=x_{i}\}=p_{ij},i,j=1,2,…$，我们称$P\{X=x,Y=y\}=p_{ij},i,j=1,2,....$为二维离散型随机变量(X,Y)的分布律，或随机变量X和Y的联合分布律。

- 似然函数：若总体X属离散型，其分布律$P{X=x}=p(x;\theta)$，$\theta$为待估参数，设$X_{1}$,$X_{2}$,....$X_{n}$是来自X的样本，$X_{1}$,$X_{2}$,....$X_{n}$的联合分布律为：

  ​							$\prod_{i=1} ^ np(x;\theta)$

  又设$x_{1}$,$x_{2}$,...$x_{n}$是相应样本$X_{1}$,$X_{2}$,....$X_{n}$的一个样本值，易得样本$X_{1}$,$X_{2}$,....$X_{n}$取到观察值$x_{1}$,$x_{2}$,…$x_{n}$的概率，亦即事件{$X_{1}=x_{1},X_{2}=x_{2},...X_{n}=x_{n}$}发生的概率为

  ​			$L(\theta)=L(x_{1}$,$x_{2}$,…$x_{n};\theta)=\prod_{i=1} ^ n p(x_{i};\theta)$

  这一概率随$\theta$的取值而变化，它是$\theta$的函数，$L(\theta)$称为样本的似然函数。

- 最大似然估计法：固定样本观察值$x_{1}$,$x_{2}$,…$x_{n}$，在$\theta$取值的可能范围内挑选使似然函数$L(x_{1},x_{2}…,x_{n};\theta)$达到最大参数值$\theta^`$，作为参数$\theta$的估计值，即取得$\theta^`$使得

  ​			$L(\theta)=L(x_{1}$,$x_{2}$,…$x_{n};\theta)=maxL(x_{1},x_{2},…x{n};\theta)$

  所求得的$\theta^`$称为参数$\theta$的最大似然估计值。

#####牛顿迭代法

曾经遇到这么一个算法题：求一个int值的开方。

该题的解法，常规的有两种，一种是二分查找，另一种则就是牛顿迭代法，并且后者要优于前者。

- 问题分析：要就得某一个数a的开方，假设开方值为x，即是求$x^2=a$的根，也等效于是求函数$f(x)=x^2-a$的根。

- 牛顿迭代法过程：

  - 首先在函数图像上找一点，假设为$(x_{1},f(x_{1}))$，以该点做函数的切线，切线方程为：$y=f^`(x1)x-f^`(x1)x_{1}f+(x_{1})$，并与x轴相交于一点$p_{1}$点$(x_{1}-(\frac{f(x_{1})}{f^`(x1)}),0)$
  - 并以$p_{1}$点做垂线，相交于$f(x)$上一点，并同样以该点做切线，并与x轴相交于一点$p_{2}$。
  - 。。。
  - 最终，与x轴的交点会收敛于根的位置

- 总结：

  由以上的推断，可以得到从右向左算起，已知与x轴第i个交点的坐标为$(x_{i},0)$，那么第i+1个交点的坐标为$(x_{i+1},0)$，其中$x_{i+1}$的值为：

    					$x_{i+1}=x_{i}-\frac{f(x_{i})}{f^`(x_{i})}$

- 代码解决：

  ```java
  public static int sqrt(int x) {
  	if(x==0) return 0;
      long r = x;
      while (r*r > x) {
           r = (r+x/r)/2;
      }
      return (int) r;
  }
  ```

#####牛顿迭代法求解最大似然估计

通过以上的案例，我们知道牛顿迭代法是可以求解方程的解的。在我们求解最大似然估计时，实际上就是求解似然函数导数为0的根。那么我们就可以通过以下的过程求解最大似然估计：

- 如果总体X属于离散型，其分布律$P{X=x}=p(x,\theta)$，设$X_{1},.X_{2}...X_{n}$是来自X的样本，$\theta$为待估参数，则$X_{1},.X_{2}...X_{n}$的联合分布律为：

  ​               						$\prod_{i=1} ^ np(x;\theta)$

- 所以可以列出事件${X_{1}=x_{1}，X_{2}=x_{2}...X_{n}=x_{n}}$发生的概率为（也就是似然函数）：

  ​				$L(\theta)=L(x_{1}$,$x_{2}$,…$x_{n};\theta)=\prod_{i=1} ^ n p(x_{i};\theta)$

- 为了求出$L(\theta)$在$\theta$处求得极值，因此$\theta$的最大似然估计值$\theta$可以从以下方程求得：

  ​				$f(\theta)=\frac{d}{d\theta}lnL(\theta)=0$

- 实际上就是求方程$f(\theta)$的根。利用上述所讲的牛顿迭代法列出，迭代方程：

  ​				$\theta:=\theta-\frac{f(\theta)}{f^`(\theta)}$




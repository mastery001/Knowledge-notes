# 安装
blog：[ mac下Spark的安装与使用](http://codingxiaxw.cn/2016/12/07/60-mac-spark/)
# RDD
核心结构：RDD，全称“弹性分布式数据集”（resilient distributed dataset）。它表示已被分区，不可变的并能够被并行操作的数据集合，不同的数据集格式对应不同的RDD实现。

RDD 是 Spark 里的数据集，分布于 RAM 或内存，或许多机器中。 一个 RDD 对象本质是多个元素的组合。它可以是包含多个元素（元组、列表、字典等）的列表。

## 结构：
1. 分区列表（数据块列表）
2. 计算分片的函数（根据父RDD计算出当前RDD）
3. 对父RDD的依赖列表（）
4. 对key-value RDD的Partitioner（可选）
5. 每个数据分片的预定义地址列表(如HDFS上的数据块的地址)（可选）

## 特点：
1. 可序列化的：RDD可以cache到内存中，每次对RDD数据集的操作之后的结果，都可以存放到内存中，下一个操作可以直接从内存中输入，省去了MapReduce大量的磁盘IO操作。
2. 不可变的
3. 失败自动重建

## 存储与分区：
RDD默认是存储于内存，但当内存不足时，RDD会降级到disk。

存储级别（根据useDisk、useMemory、deserialized、replication四个参数的组合提供了11种存储级别）：

```
val NONE = new StorageLevel(false, false, false) 
val DISK_ONLY = new StorageLevel(true, false, false) 
val DISK_ONLY_2 = new StorageLevel(true, false, false, 2) 
val MEMORY_ONLY = new StorageLevel(false, true, true) 
val MEMORY_ONLY_2 = new StorageLevel(false, true, true, 2) 
val MEMORY_ONLY_SER = new StorageLevel(false, true, false) 
val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, 2) 
val MEMORY_AND_DISK = new StorageLevel(true, true, true) 
val MEMORY_AND_DISK_2 = new StorageLevel(true, true, true, 2) 
val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false) 
val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, 2)
```

## 生成方式：
1. 从HDFS文件中读取生成
2. 从父RDD转换得到子RDD

Transformations & Actions
- Transformations(转换):转换操作包括（map, filter, groupBy, join等），结果返回一个RDD，转换操作是Lazy的，Spark在进行RDD转换操作是不会立即生效操作，而是等到Actions时才会进行生效
- Actions(操作):Actions包括（count, collect, save等），返回值不是一个RDD；其结果会返回一个结果或将数据写入到存储系统中。触发Spark启动计算的动因。

## Lineage（血统/血脉之力）

[TOC]

# 算法

## Mathematical formulation

### L-P范数

范数是一种强化了的距离概念。包括

1. 向量范数：向量空间中向量的大小
2. 矩阵范数：矩阵引起的变化的大小

公式定义：$Lp=\sqrt[p]{\sum\limits_{1}^n  x_i^p}，x=(x_1,x_2,\cdots,x_n)$


根据P 的变化，范数也有着不同的变化，一个经典的有关P范数的变化图如下： 
![这里写图片描述](http://img.blog.csdn.net/20160623222921977)

1. 当p=0时，即L0范数，主要被用来度量向量中非零元素的个数

2. 当p=1时，即L1范数(也被称作稀疏规则算子—Lasso regularization)，表示向量x中非零元素的绝对值之和；主要用来度量两个向量间的差异；(曼哈顿距离、最小绝对误差) 如绝对误差和(Sum of Absolute Difference)
   $$
   SAD(x_1,x_2) = \sum_i \left|x_{1i} - x_{2i}\right|
   $$

3. 当p=2时，即L2范数，表示向量元素的平方和再开方。常见的L2范数有欧式距离公式，或如平方差和(Sum of Squared Difference)
   $$
   SAD(x_1 , x_2) = \sum_i (x_{1i} - x_{2i})^2
   $$

4. 当p=∞时，也就是L-∞范数，主要被用来度量向量元素的最大值

   ​

## 监督学习

监督学习(supervised learning)：利用样本输入和期望输出来学习如何预测的技术

1. K-近邻
2. 决策树(decision trees)
3. 梯度下降/上升(gradient-descent / gradient-boosted )
4. 逻辑回归(logistis regression)
5. 贝叶斯过滤(naive Bayes)
6. 交替最小二乘法(Alternative least squares)
7. 支持向量机(SVMs)
8. 随机森林(random forests)
9. 神经网络

## 无监督学习

无监督学习(unsupervised learning)：从一组数据中找寻某种结构

1. 聚类
2. 负矩阵因式分解(non-negative matrix factorization)
3. 自组织映射(self-organizing maps)

# ML步骤

1. 收集数据，筛选特征
2. 模型算法选取
3. 生成cost function，得出假设函数
4. 新值代入假设函数

# K-近邻

步骤如下：

1. 计算已知类别数据集中的点与当前点的距离(欧式距离公式)
2. 按照距离递增排序
3. 选取与当前点距离最小的前k个点
4. 确定前k个点所在类别出现的概率
5. 返回前k个点出现概率最高的类别(即当前点预测分类)



# 决策树

假设有n个特征，依次根据数据增益情况求出最优特征，然后根据特征求出对应的分支

1. 根据数据集选取出最佳特征
2. 计算该特征对应的值分别对应的结果标签--- 可能是结果标签，也可能是其他特征的决策树